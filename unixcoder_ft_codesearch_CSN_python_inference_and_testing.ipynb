{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XxUpXvnJsTH1"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rN86fUkAsNes"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super(Model, self).__init__()\n",
        "        self.encoder = encoder\n",
        "\n",
        "    def forward(self, code_inputs=None, nl_inputs=None):\n",
        "        if code_inputs is not None:\n",
        "            outputs = self.encoder(code_inputs,attention_mask=code_inputs.ne(1))[0]\n",
        "            outputs = (outputs*code_inputs.ne(1)[:,:,None]).sum(1)/code_inputs.ne(1).sum(-1)[:,None]\n",
        "            return torch.nn.functional.normalize(outputs, p=2, dim=1)\n",
        "        else:\n",
        "            outputs = self.encoder(nl_inputs,attention_mask=nl_inputs.ne(1))[0]\n",
        "            outputs = (outputs*nl_inputs.ne(1)[:,:,None]).sum(1)/nl_inputs.ne(1).sum(-1)[:,None]\n",
        "            return torch.nn.functional.normalize(outputs, p=2, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLb-HxEZsuw-",
        "outputId": "97b59068-38de-4c69-d306-3fdc60c18cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yKHq0jvT17Oe"
      },
      "outputs": [],
      "source": [
        "# Path to your model.bin file on Google Drive\n",
        "# model_path = '/content/drive/My Drive/model (7).bin'\n",
        "model_path = r\"C:\\Users\\agianolini\\OneDrive - ANDES WEALTH MANAGEMENT SA\\Desktop\\research-assistant-main\\model (7).bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QekAft6MhZbD"
      },
      "outputs": [],
      "source": [
        "class CodeSearcher:\n",
        "    def __init__(self, model_path, code_snippets, device=None):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") if device is None else device\n",
        "        self.tokenizer = RobertaTokenizer.from_pretrained('microsoft/unixcoder-base')\n",
        "        self.model = self.load_model(model_path)\n",
        "        self.code_snippets = code_snippets\n",
        "        self.code_embeddings = self.generate_code_embeddings(code_snippets)\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        model = RobertaModel.from_pretrained('microsoft/unixcoder-base')\n",
        "        model = Model(model)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
        "        model.to(self.device)\n",
        "        model.eval()\n",
        "        return model\n",
        "\n",
        "    def generate_code_embeddings(self, code_snippets):\n",
        "        embeddings = []\n",
        "        for snippet in code_snippets:\n",
        "            inputs = self.tokenizer.encode_plus(snippet, add_special_tokens=True, max_length=256, truncation=True, padding='max_length', return_tensors='pt')\n",
        "            with torch.no_grad():\n",
        "                embedding = self.model(code_inputs=inputs['input_ids'].to(self.device))\n",
        "            embeddings.append(embedding.cpu().numpy())\n",
        "        return np.vstack(embeddings)\n",
        "\n",
        "    def get_query_embedding(self, query):\n",
        "        inputs = self.tokenizer.encode_plus(query, add_special_tokens=True, max_length=128, truncation=True, padding='max_length', return_tensors='pt')\n",
        "        with torch.no_grad():\n",
        "            embedding = self.model(code_inputs=inputs['input_ids'].to(self.device))\n",
        "        return embedding.cpu().numpy()\n",
        "\n",
        "    def get_similarity_search(self, query, k):\n",
        "        query_embedding = self.get_query_embedding(query)\n",
        "        similarities = 1 - cdist(query_embedding, self.code_embeddings, 'cosine').flatten()\n",
        "\n",
        "        # Get top-k indices\n",
        "        top_k_indices = np.argsort(similarities)[-k:]\n",
        "\n",
        "        # Create a dictionary for the top k results\n",
        "        results = {}\n",
        "        for index in reversed(top_k_indices):\n",
        "            snippet_info = {\n",
        "                'index': index,\n",
        "                'snippet': self.code_snippets[index],\n",
        "                'similarity': similarities[index]\n",
        "            }\n",
        "            results[f'top_{k}'] = snippet_info\n",
        "            k -= 1\n",
        "\n",
        "        return results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dTqh87OstcmN"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "code_snippets = [\"print('Hello, world!')\", \"my ass is like the sky!\", \"for i in range(10): print(i)\"]  # Your collection of code snippets\n",
        "searcher = CodeSearcher(model_path, code_snippets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsnIFjPt1s--",
        "outputId": "3f73bbf8-11d6-47ae-bfb9-e5306159d007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top K similar items: \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'top_3': {'index': 0,\n",
              "  'snippet': \"print('Hello, world!')\",\n",
              "  'similarity': 0.5174323756887338},\n",
              " 'top_2': {'index': 1,\n",
              "  'snippet': 'my ass is like the sky!',\n",
              "  'similarity': 0.3868753964239914},\n",
              " 'top_1': {'index': 2,\n",
              "  'snippet': 'for i in range(10): print(i)',\n",
              "  'similarity': 0.25039381632295665}}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"print hello world\"\n",
        "k = 3\n",
        "t = searcher.get_similarity_search(query, k)\n",
        "\n",
        "print(\"Top K similar items: \\n\")\n",
        "t"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
